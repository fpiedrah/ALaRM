# ALaRM: Align Language Models via Hierarchical Rewards Modeling
This repository will host the code for the paper [ALaRM: Align Language Models via Hierarchical Rewards Modeling](https://arxiv.org/abs/2403.06754).

You can refer to our [project page](https://alarm-fdu.github.io/) for a quick project overview.

## Code Release
We are actively working on preparing the code for release and aim to make it available as soon as possible. Upon the code release, this README will be updated with instructions.

Thank you for your interest in ALaRM!
